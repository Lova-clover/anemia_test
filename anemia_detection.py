import streamlit as st
import cv2
import numpy as np
import torch
import torch.nn as nn
from torchvision import models, transforms
import torchvision.transforms as T
from PIL import Image
from streamlit_webrtc import webrtc_streamer, VideoTransformerBase, WebRtcMode

# -----------------------
# 1. ë””ë°”ì´ìŠ¤ ì„¤ì •
# -----------------------
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# -----------------------
# 2. í´ë˜ìŠ¤ ë ˆì´ë¸” ë§µí•‘
# -----------------------
label_map = {0: "Anemia", 1: "Non-Anemia"}

# -----------------------
# 3. ResNet18 ëª¨ë¸ ì •ì˜ ë° ê°€ì¤‘ì¹˜ ë¡œë“œ
# -----------------------
@st.cache_resource
def load_model():
    model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)
    for name, param in model.named_parameters():
        if not (name.startswith("layer3") or name.startswith("layer4") or name.startswith("fc")):
            param.requires_grad = False

    num_ftrs = model.fc.in_features
    model.fc = nn.Sequential(
        nn.Dropout(0.3),
        nn.Linear(num_ftrs, 128),
        nn.ReLU(inplace=True),
        nn.Dropout(0.3),
        nn.Linear(128, 2)
    )

    checkpoint_path = "best_fold3.pth"
    state_dict = torch.load(checkpoint_path, map_location=device)
    model.load_state_dict(state_dict)

    model = model.to(device)
    model.eval()
    return model

model = load_model()

# -----------------------
# 4. ì „ì²˜ë¦¬ ì •ì˜
# -----------------------
IMG_SIZE = 224
val_transform = T.Compose([
    T.Resize((IMG_SIZE, IMG_SIZE)),
    T.ToTensor(),
    T.Normalize(mean=[0.485, 0.456, 0.406],
                std=[0.229, 0.224, 0.225]),
])

# -----------------------
# 5. Haar Cascade ë¡œë“œ (ëˆˆ ì˜ì—­ ê²€ì¶œìš©)
# -----------------------
eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + "haarcascade_eye.xml")

# -----------------------
# 6. BÃ©zier frame ì¢Œí‘œ ê³„ì‚° (íœ´ëŒ€í° ê¸°ì¤€ìœ¼ë¡œ ì‘ê²Œ í¬ê¸°ë¥¼ ì¡°ì ˆí•˜ì˜€ë‹¤)
# -----------------------
def get_conjunctiva_bezier_bbox(image_size):
    # --- ì´ ë¶€ë¶„ì„ ì¡°ì ˆí•˜ì—¬ ëª¨ë°”ì¼ í™˜ê²½ì— ë§ê²Œ í”„ë ˆì„ í¬ê¸°ë¥¼ ì¡°ì •í•˜ì˜€ë‹¤. ---
    # frame_width_ratio: í”„ë ˆì„ì˜ ê°€ë¡œ í­ ë¹„ìœ¨ (ì „ì²´ ë„ˆë¹„ ëŒ€ë¹„)
    # frame_height_ratio: í”„ë ˆì„ì˜ ì„¸ë¡œ í­ ë¹„ìœ¨ (ì „ì²´ ë†’ì´ ëŒ€ë¹„)
    # center_x_ratio: í”„ë ˆì„ ì¤‘ì•™ì˜ ê°€ë¡œ ìœ„ì¹˜ (ì „ì²´ ë„ˆë¹„ ëŒ€ë¹„)
    # center_y_ratio: í”„ë ˆì„ ì¤‘ì•™ì˜ ì„¸ë¡œ ìœ„ì¹˜ (ì „ì²´ ë†’ì´ ëŒ€ë¹„)
    
    w, h = image_size
    
    frame_width_ratio = 0.10   
    frame_height_ratio = 0.03  
    
    center_x_ratio = 0.5
    center_y_ratio = 0.55

    left = int(w * (center_x_ratio - frame_width_ratio / 2))
    right = int(w * (center_x_ratio + frame_width_ratio / 2))
    upper = int(h * (center_y_ratio - frame_height_ratio / 2))
    lower = int(h * (center_y_ratio + frame_height_ratio / 2))

    return left, upper, right, lower

# -----------------------
# 7. BÃ©zier ê³¡ì„  ì  ê³„ì‚° í—¬í¼ (ê²°ë§‰ ë¶€ë¶„ ì •í™•íˆ cropí•˜ê¸° ìœ„í•¨)
# -----------------------
def cubic_bezier_points(p0, p1, p2, p3, n=200):
    t = np.linspace(0, 1, n)
    pts = []
    for ti in t:
        x = (1 - ti)**3 * p0[0] + 3 * (1 - ti)**2 * ti * p1[0] + 3 * (1 - ti) * ti**2 * p2[0] + ti**3 * p3[0]
        y = (1 - ti)**3 * p0[1] + 3 * (1 - ti)**2 * ti * p1[1] + 3 * (1 - ti) * ti**2 * p2[1] + ti**3 * p3[1]
        pts.append((int(x), int(y)))
    return pts

# -----------------------
# 8. BÃ©zier í”„ë ˆì„ ì˜¤ë²„ë ˆì´
# -----------------------
def draw_bezier_frame(cv_img: np.ndarray) -> np.ndarray:
    h, w, _ = cv_img.shape
    left, upper, right, lower = get_conjunctiva_bezier_bbox((w, h))
    
    frame_w = max(1, right - left)
    frame_h = max(1, lower - upper)

    # ìœ— ê³¡ì„  ì œì–´ì 
    p0 = (left, upper)
    p1 = (left + int(frame_w * 0.25), upper + int(frame_h * 0.4))
    p2 = (right - int(frame_w * 0.25), upper + int(frame_h * 0.4))
    p3 = (right, upper)
    top_curve = cubic_bezier_points(p0, p1, p2, p3, n=200)

    # ì•„ë« ê³¡ì„  ì œì–´ì 
    p0_b = (right, upper)
    p1_b = (right + int(frame_w * 0.1), lower + int(frame_h * 0.05))
    p2_b = (left - int(frame_w * 0.1), lower + int(frame_h * 0.05))
    p3_b = (left, upper)
    bottom_curve = cubic_bezier_points(p0_b, p1_b, p2_b, p3_b, n=200)

    pts = np.array(top_curve + bottom_curve, dtype=np.int32)
    cv2.polylines(cv_img, [pts], isClosed=True, color=(0, 255, 0), thickness=2)
    return cv_img

# -----------------------
# 9. BÃ©zier í”„ë ˆì„ ë‚´ë¶€ë§Œ ì¶”ì¶œí•˜ê³  ì™¸ë¶€ë¥¼ í°ìƒ‰ìœ¼ë¡œ ë§ˆìŠ¤í‚¹
# -----------------------
def extract_and_mask_bezier_region(img_bgr: np.ndarray) -> np.ndarray:
    # ì´ë¯¸ì§€ë¥¼ ë°›ì•„ì„œ í”„ë ˆì„ ë‚´ë¶€ ì˜ì—­ë§Œ ì¶”ì¶œí•˜ê³ , ì™¸ë¶€ë¥¼ í°ìƒ‰ìœ¼ë¡œ ë§ˆìŠ¤í‚¹í•©ë‹ˆë‹¤. (í•™ìŠµ ëª¨ë¸ì˜ íŠ¹ì„± ë•Œë¬¸ì—)
    h, w, _ = img_bgr.shape
    left, upper, right, lower = get_conjunctiva_bezier_bbox((w, h))
    
    # í”„ë ˆì„ì˜ í­ê³¼ ë†’ì´ê°€ 0ì´ ë˜ì§€ ì•Šë„ë¡ ìµœì†Œê°’ ì„¤ì •
    frame_w = max(1, right - left)
    frame_h = max(1, lower - upper)

    # BÃ©zier ê³¡ì„  ì¢Œí‘œ ê³„ì‚°
    p0 = (left, upper)
    p1 = (left + int(frame_w * 0.25), upper + int(frame_h * 0.4))
    p2 = (right - int(frame_w * 0.25), upper + int(frame_h * 0.4))
    p3 = (right, upper)
    top_curve = cubic_bezier_points(p0, p1, p2, p3, n=200)

    p0_b = (right, upper)
    p1_b = (right + int(frame_w * 0.1), lower + int(frame_h * 0.05))
    p2_b = (left - int(frame_w * 0.1), lower + int(frame_h * 0.05))
    p3_b = (left, upper)
    bottom_curve = cubic_bezier_points(p0_b, p1_b, p2_b, p3_b, n=200)

    polygon = np.array(top_curve + bottom_curve, dtype=np.int32)

    # í° ë°°ê²½ ì´ë¯¸ì§€ ìƒì„±
    white_bg = np.ones_like(img_bgr) * 255

    # ë§ˆìŠ¤í¬ ìƒì„± (BÃ©zier í”„ë ˆì„ ë‚´ë¶€ë¥¼ 255ë¡œ ì±„ì›€)
    mask = np.zeros((h, w), dtype=np.uint8)
    cv2.fillPoly(mask, [polygon], 255)

    # ë§ˆìŠ¤í¬ëœ ë¶€ë¶„ë§Œ ì›ë³¸ ì´ë¯¸ì§€, ë‚˜ë¨¸ì§€ëŠ” í°ìƒ‰
    combined = np.where(mask[..., None] == 255, img_bgr, white_bg)

    # bounding box ê¸°ì¤€ìœ¼ë¡œ í¬ë¡­
    cropped = combined[upper:lower, left:right]
    if cropped.shape[0] == 0 or cropped.shape[1] == 0:
        # ë„ˆë¬´ ì‘ìœ¼ë©´ í°ìƒ‰ ë°˜í™˜
        return np.ones((IMG_SIZE, IMG_SIZE, 3), dtype=np.uint8) * 255

    return cropped

# -----------------------
# 10. ëˆˆ ì˜ì—­(ROI) ê²€ì¶œ í›„ í™ì±„(iris) ê²€ì¶œ
# -----------------------
def detect_eye_region(gray_img):
    """
    Haar Cascadeë¡œ ëˆˆ íŒ¨ì¹˜(ROI)ë¥¼ ê²€ì¶œ.
    ì„±ê³µ ì‹œ (x, y, w, h) ë°˜í™˜, ì—†ìœ¼ë©´ None.
    """
    eyes = eye_cascade.detectMultiScale(gray_img, scaleFactor=1.1, minNeighbors=4, minSize=(30,30))
    if len(eyes) == 0:
        return None
    # ê°€ì¥ ë„“ì€ ëˆˆ ì˜ì—­ ì„ íƒ
    eyes = sorted(eyes, key=lambda e: e[2]*e[3], reverse=True)
    ex, ey, ew, eh = eyes[0]
    return (ex, ey, ew, eh)

def detect_iris_circle(gray_img, eye_rect=None):
    """
    HoughCirclesë¡œ í™ì±„(iris) ê²€ì¶œ.
    eye_rectê°€ ì£¼ì–´ì§€ë©´ ê·¸ ì˜ì—­ ë‚´ë¶€ì—ì„œë§Œ íƒìƒ‰.
    ì„±ê³µ ì‹œ iris_mask(ì› ë‚´ë¶€=255), (x, y, r) ë°˜í™˜.
    ì‹¤íŒ¨ ì‹œ None, None ë°˜í™˜.
    """
    # ROI ì„¤ì •: eye_rectê°€ ìˆìœ¼ë©´ ê·¸ ë¶€ë¶„ë§Œ ì‚¬ìš©
    if eye_rect is not None:
        ex, ey, ew, eh = eye_rect
        roi_gray = gray_img[ey:ey+eh, ex:ex+ew]
        offset = (ex, ey)
    else:
        roi_gray = gray_img
        offset = (0, 0)

    # 1) CLAHE ì ìš©í•˜ì—¬ ëŒ€ë¹„ í–¥ìƒ
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    roi_clahe = clahe.apply(roi_gray)

    # 2) GaussianBlurë¡œ ë…¸ì´ì¦ˆ ì œê±° (ë” ë¶€ë“œëŸ¬ìš´ ê²½ê³„ í™•ë³´)
    blurred = cv2.GaussianBlur(roi_clahe, (9, 9), 2)

    rows = roi_gray.shape[0]

    # 3) HoughCircles íŒŒë¼ë¯¸í„° ì¡°ì •
    circles = cv2.HoughCircles(
        blurred,
        cv2.HOUGH_GRADIENT,
        dp=1.2,                            # ëˆ„ê²© ë¹„ìœ¨: 1.2ë¡œ ì•½ê°„ ë†’ì—¬ ì‘ì€ ì›ë„ ê°ì§€
        minDist=rows / 4,                 # ê°™ì€ ì›ì´ ì—¬ëŸ¬ ë²ˆ ê°ì§€ë˜ì§€ ì•Šë„ë¡ ê±°ë¦¬ ì œí•œ
        param1=50,                        # Canny ì—ì§€ì˜ upper threshold
        param2=20,                        # accumulator threshold: ë‚®ì¶œìˆ˜ë¡ ë” ë§ì€ ì› ê°ì§€
        minRadius=int(rows * 0.10),       # ìµœì†Œ ë™ê³µ í¬ê¸° (ROI ë†’ì´ì˜ 10%)
        maxRadius=int(rows * 0.25)        # ìµœëŒ€ ë™ê³µ í¬ê¸° (ROI ë†’ì´ì˜ 25%)
    )
    if circles is None:
        return None, None

    circles = np.round(circles[0, :]).astype(int)
    # ë™ê³µ(ê²€ì€ì›)ì€ ë°˜ì§€ë¦„ì´ ì‘ì€ ìª½ì— ê°€ê¹ê¸° ë•Œë¬¸ì— ë°˜ì§€ë¦„ ì‘ì€ ìˆœì„œë¡œ ì •ë ¬
    circles = sorted(circles, key=lambda c: c[2])
    cx, cy, r = circles[0]

    # 4) ROI ì¢Œí‘œë¥¼ ì „ì²´ ì´ë¯¸ì§€ ì¢Œí‘œë¡œ ë³´ì •
    cx_full = cx + offset[0]
    cy_full = cy + offset[1]

    # 5) ë§ˆìŠ¤í¬ ìƒì„±
    iris_mask = np.zeros_like(gray_img, dtype=np.uint8)
    cv2.circle(iris_mask, (cx_full, cy_full), r, 255, thickness=-1)

    return iris_mask, (cx_full, cy_full, r)

def generate_sclera_mask_by_rule(shape, iris_center, iris_radius):
    """
    í™ì±„ ì¤‘ì‹¬ì—ì„œ 1.25*r ì•„ë˜, ë°˜ì§€ë¦„ 0.35*r ì›ì„ ê³µë§‰(sclera) ì˜ì—­ìœ¼ë¡œ ìƒì„±.
    """
    mask = np.zeros(shape, dtype=np.uint8)
    if iris_center is None or iris_radius is None:
        return mask, (0, 0, 0)
    x, y = iris_center
    sclera_cx = int(round(x))
    sclera_cy = int(round(y + 1.25 * iris_radius))
    sclera_r = int(round(0.35 * iris_radius))
    cv2.circle(mask, (sclera_cx, sclera_cy), sclera_r, 255, thickness=-1)
    return mask, (sclera_cx, sclera_cy, sclera_r)

# -----------------------
# 11. ê³µë§‰ ë°ê¸° ê³„ì‚° í•¨ìˆ˜
# -----------------------
def compute_sclera_brightness(gray_img, sclera_mask):
    """
    ê³µë§‰(sclera) ë§ˆìŠ¤í¬ ì˜ì—­ í‰ê·  ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë°ê¸° ë°˜í™˜.
    í”½ì…€ì´ ì—†ìœ¼ë©´ 1.0 ë¦¬í„´.
    """
    pixels = gray_img[sclera_mask == 255]
    return float(np.mean(pixels)) if pixels.size > 0 else 1.0

# -----------------------
# 12. ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬ë¥¼ ìœ„í•œ Transformer
# -----------------------
class ConjunctivaProcessor(VideoTransformerBase):
    def __init__(self):
        self.last_frame_bgr = None

    def transform(self, frame):
        img_bgr = frame.to_ndarray(format="bgr24")
        overlaid = draw_bezier_frame(img_bgr.copy())
        self.last_frame_bgr = img_bgr.copy()
        return overlaid

# -----------------------
# 13. Streamlit í˜ì´ì§€ êµ¬ì„±
# -----------------------
st.title("ğŸ“¸ ê²°ë§‰ ì‚¬ì§„ìœ¼ë¡œ ë¹ˆí˜ˆ ì˜ˆì¸¡ ì•±")

st.markdown(
    """
    **ì´ ì•±ì€ BÃ©zier í”„ë ˆì„ ì•ˆì˜ ê²°ë§‰ì„ ì˜ë¼ë‚¸ ë’¤, ëˆˆìœ¼ë¡œ í™ì±„ë¥¼ ì°¾ê³   
    ê³µë§‰ ë°ê¸°ë¥¼ ê³„ì‚°í•˜ì—¬ ë°ê¸° ì •ê·œí™” í›„ ResNet18 ëª¨ë¸ë¡œ ë¹ˆí˜ˆ ì—¬ë¶€ë¥¼ ì˜ˆì¸¡í•©ë‹ˆë‹¤.**

    **ì‚¬ìš©ë²•:**
    1. ì•„ë˜ 'Start camera' ë²„íŠ¼ì„ ëˆŒëŸ¬ ì¹´ë©”ë¼ë¥¼ ì¼œì„¸ìš”.
    2. ì¹´ë©”ë¼ í”¼ë“œì— ë‚˜íƒ€ë‚˜ëŠ” **ì´ˆë¡ìƒ‰ í”„ë ˆì„ ì•ˆì— ê²°ë§‰ ë¶€ë¶„ì„ ë§ì¶°ì£¼ì„¸ìš”.**
    3. 'ì‚¬ì§„ ì°ê¸° & ì˜ˆì¸¡' ë²„íŠ¼ì„ ëˆŒëŸ¬ ì´¬ì˜í•˜ë©´, í”„ë ˆì„ ì•ˆì˜ ì˜ì—­ë§Œ ì¶”ì¶œí•˜ì—¬ ì˜ˆì¸¡í•©ë‹ˆë‹¤.
    """
)

# 13.1. webrtc_streamer ì„¤ì • (ì¹´ë©”ë¼ í•´ìƒë„ ìµœëŒ€ë¡œ ìš”ì²­)
webrtc_ctx = webrtc_streamer(
    key="conjunctiva_capture_stream",
    mode=WebRtcMode.SENDRECV,
    rtc_configuration={
        "iceServers": [{"urls": ["stun:stun.l.google.com:19302"]}]
    },
    video_processor_factory=ConjunctivaProcessor,
    media_stream_constraints={
        "video": {
            "width": {"ideal": 1920}, # Full HD
            "height": {"ideal": 1080},
            "frameRate": {"ideal": 30},
        },
        "audio": False,
    },
    async_processing=True,
)

# -----------------------
# 14. â€œì‚¬ì§„ ì°ê¸° & ì˜ˆì¸¡â€ ë²„íŠ¼
# -----------------------
if webrtc_ctx.video_processor:
    if st.button("ì‚¬ì§„ ì°ê¸° & ì˜ˆì¸¡"):
        captured_bgr = webrtc_ctx.video_processor.last_frame_bgr
        if captured_bgr is None:
            st.warning("ì¹´ë©”ë¼ í”„ë ˆì„ì´ ì•„ì§ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì ì‹œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”.")
        else:
            # (1) BÃ©zier í”„ë ˆì„ ì˜ì—­ë§Œ ì¶”ì¶œ(ë§ˆìŠ¤í‚¹+í¬ë¡­) â†’ BGR numpy
            cropped_bgr = extract_and_mask_bezier_region(captured_bgr)

            # (2) ëˆˆ ì˜ì—­(ROI) ê²€ì¶œ â†’ í™ì±„(Hough Circle) ê²€ì¶œ
            gray_full = cv2.cvtColor(captured_bgr, cv2.COLOR_BGR2GRAY)
            eye_rect = detect_eye_region(gray_full)

            iris_mask, iris_info = detect_iris_circle(gray_full, eye_rect)
            # iris_infoê°€ Noneì´ë©´ ì „ì²´ ì´ë¯¸ì§€ì—ì„œ ì¬ì‹œë„
            if iris_info is None:
                iris_mask, iris_info = detect_iris_circle(gray_full, None)

            # (3) ê³µë§‰ ë§ˆìŠ¤í¬ ìƒì„± â†’ ê³µë§‰ ë°ê¸° ê³„ì‚°
            sclera_mask, sclera_info = generate_sclera_mask_by_rule(
                gray_full.shape,
                iris_info[:2] if iris_info else None,
                iris_info[2] if iris_info else None
            )
            sclera_brightness = compute_sclera_brightness(gray_full, sclera_mask)

            # (4) ë°ê¸° ì •ê·œí™”: cropped_bgrì„ ê³µë§‰ í‰ê·  ë°ê¸° ê¸°ì¤€ìœ¼ë¡œ ìŠ¤ì¼€ì¼ë§
            if iris_info is not None and sclera_brightness > 0:
                target_brightness = 128.0
                alpha = target_brightness / (sclera_brightness + 1e-6)
                cropped_float = cropped_bgr.astype(np.float32) * alpha
                cropped_float = np.clip(cropped_float, 0, 255).astype(np.uint8)
            else:
                cropped_float = cropped_bgr.copy()

            # (5) RGB ìˆœì„œë¡œ ë³€í™˜í•˜ì—¬ PIL.Image ìƒì„±
            cropped_rgb = cv2.cvtColor(cropped_float, cv2.COLOR_BGR2RGB)
            pil_input = Image.fromarray(cropped_rgb)

            # (6) ResNet18 ì˜ˆì¸¡
            input_tensor = val_transform(pil_input).unsqueeze(0).to(device)
            with torch.no_grad():
                logits = model(input_tensor)
                probs = torch.softmax(logits, dim=1)[0]
                pred_label = int(probs.argmax())
                confidence = float(probs.max().item())
            diagnosis = label_map[pred_label]

            # (7) ì‹œê°í™”ë¥¼ ìœ„í•´ ìœ¤ê³½ì„  ê·¸ë¦¬ê¸°
            vis = captured_bgr.copy()
            vis_rgb = cv2.cvtColor(vis, cv2.COLOR_BGR2RGB)

            # í™ì±„ ì› (ë¹¨ê°„ìƒ‰)
            if iris_info:
                ix, iy, ir = iris_info
                cv2.circle(vis_rgb, (ix, iy), ir, (255, 0, 0), 2)

            # ê³µë§‰ ì› (ë…¸ë€ìƒ‰)
            scx, scy, scr = sclera_info
            if (scx, scy, scr) != (0, 0, 0):
                cv2.circle(vis_rgb, (scx, scy), scr, (255, 255, 0), 2)

            # BÃ©zier ê²°ë§‰ ìœ¤ê³½ (ë…¹ìƒ‰)
            h, w, _ = captured_bgr.shape
            left, upper, right, lower = get_conjunctiva_bezier_bbox((w, h))
            polygon_pts = np.array(
                cubic_bezier_points((left, upper),
                                   (left + int((right-left)*0.25), upper + int((lower-upper)*0.4)),
                                   (right - int((right-left)*0.25), upper + int((lower-upper)*0.4)),
                                   (right, upper), n=200)
                + cubic_bezier_points((right, upper),
                                      (right + int((right-left)*0.1), lower + int((lower-upper)*0.05)),
                                      (left - int((right-left)*0.1), lower + int((lower-upper)*0.05)),
                                      (left, upper), n=200),
                dtype=np.int32
            )
            cv2.polylines(vis_rgb, [polygon_pts], isClosed=True, color=(0, 255, 0), thickness=2)

            # (8) ê²°ê³¼ ì¶œë ¥
            st.subheader("ì´¬ì˜ ì§í›„: í™ì±„â€†/â€†ê³µë§‰â€†/â€†ê²°ë§‰ ROI ì‹œê°í™”")
            st.image(vis_rgb, use_container_width=True)

            st.subheader("ëª¨ë¸ ì…ë ¥ìš© ê²°ë§‰ ì´ë¯¸ì§€ (ë°ê¸° ë³´ì • í›„)")
            st.image(pil_input, use_container_width=True)

            st.subheader("ì˜ˆì¸¡ ê²°ê³¼")
            st.write(f"- **ì§„ë‹¨:** {diagnosis}")
            st.write(f"- **ì‹ ë¢°ë„:** {confidence:.4f}")
            st.progress(confidence)

            if confidence < 0.65:
                st.info("ëª¨ë¸ í™•ì‹ ë„ê°€ ë‚®ìŠµë‹ˆë‹¤. ì¡°ëª…Â·í™”ì§ˆì„ ê°œì„ í•˜ê³  ì¬ì´¬ì˜í•´ ë³´ì„¸ìš”.")
else:
    st.info("ì¹´ë©”ë¼ë¥¼ ì¼œë ¤ë©´ ìœ„ â€˜Start cameraâ€™ ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")
